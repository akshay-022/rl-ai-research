# RL Task for LLM Training - Take Home Assignment

## Objective

Your objective is to create an RL task for LLM training. An RL task consists of a prompt, along with some tools and data, and a way to verify whether the task has been completed successfully. The task should teach the model a skill useful in the normal work of an AI/ML engineer or researcher. The task should also satisfy the pass-rate requirements. We've provided some example tasks below.

You'll need an Anthropic API key. We don't expect tasks to use more than a few dollars in inference cost.

For inspiration, you can take a look at SWE_Bench_Pro, which is a collection of realistic software engineering style tasks. Unlike SWE-Bench, which is focused on software engineering, we are interested in tasks related to AI/ML research and engineering.

---

## Requirements

- The task should resemble the kinds of things an AI/ML engineer or AI/ML researcher might do

- For each task the model must succeed between 10% and 40% of the time. You can measure this by running a task against the model at least 10 times and averaging.

- The prompt must precisely encapsulate what's verified by the grading function.

- Every possible correct solution should be allowed by the grader.
  - For example, avoid checking for exact match against a string of code when other solutions exist.

- Every requirement contained in the prompt should be checked.
  - For example, if the prompt asks for a dataset filtered by a certain criteria, it should be very difficult to guess the correct answer without having correctly performed filtering.

- The task should teach the model something interesting and novel, or address a general weakness in the model.

- There should be multiple approaches to solving the task, and the model should fail the task for a variety of reasons, and not just one reason. In your documentation, make sure to explain the ways in which the model fails at your task, when it fails.

- The model shouldn't fail for task-unrelated reasons like not being good at using the tools it's given. You may need to modify the tools so that they're suitable for the model.

- Make sure the task is not failing due to too few MAX_STEPS or MAX_TOKENS. A good task fails because the model is missing some capability, knowledge, or understanding, not due to constrained resources.

- The task should be concise and easy to review by a human.

- The prompt should not have any extra information or hints unless absolutely necessary to achieve the required pass rate.

- Good submissions can be written with less than 300 lines of code (task instructions, grading, maybe a custom tool, maybe a script to download a dataset or repository).

- You should not use AI to write your submission.

- The task should be run with claude-haiku-4-5. If the task is too hard for Haiku (0% pass rate), you can try changing to Sonnet or Opus. However, this will be more expensive in inference compute.

---

## Example Task Ideas

(Your task doesn't have to be any of these! This is just for illustrative purposes)

- Implement a technique from an ML paper
- Ask the model to write and optimize a CUDA kernel
- Problems related to training/inference in modern LLMs (tokenization, vLLM, SGLang, quantization, speculative decoding, etc)
- A difficult problem you encountered during your AI/ML research or engineering experience

---

## What Not To Do

- Ask the model to clean a dataset
- Ask the model to compute simple metrics (F1 score, TF-IDF, etc)
- Ideas generated by an LLM â€” we want to see your creativity, experience, and expertise

---

## Tips

- We are looking for high (human) effort, creative task selection, and for you to demonstrate an advanced understanding of modern AI research/engineering.

- This and your resume are the only pieces of information we have to evaluate you. Try to stand out!

- Your goal is to show us your strengths, not simply to complete the assignment.

- If you have unique expertise (low-level GPU/TPU programming, experience with large-scale distributed training, research publications, etc) please try to highlight that experience!
